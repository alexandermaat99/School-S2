{"cells":[{"cell_type":"markdown","metadata":{"id":"E6QnnVUzmJnQ"},"source":["### READ ME\n","\n","Use the code blocks below to answer each quiz question. Only print the output required for each question. Do not edit the comments at the top of each code cell. Otherwise, the auto-grader may misinterpret your results. See Question 0 as an an example of how to complete a task (leave it in your notebook; don't delete it):"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"elapsed":115,"status":"ok","timestamp":1636478453992,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"Fvzzw3w-mAUN","outputId":"379d4442-8c70-483c-90c8-a4ff5d1ea6d6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Col1</th>\n","      <th>Col2</th>\n","      <th>Col3</th>\n","      <th>Col4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Row1</th>\n","      <td>Row1/Col1</td>\n","      <td>Row1/Col2</td>\n","      <td>Row1/Col3</td>\n","      <td>Row1/Col4</td>\n","    </tr>\n","    <tr>\n","      <th>Row2</th>\n","      <td>Row2/Col1</td>\n","      <td>Row2/Col2</td>\n","      <td>Row2/Col3</td>\n","      <td>Row2/Col4</td>\n","    </tr>\n","    <tr>\n","      <th>Row3</th>\n","      <td>Row3/Col1</td>\n","      <td>Row3/Col2</td>\n","      <td>Row3/Col3</td>\n","      <td>Row3/Col4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Col1       Col2       Col3       Col4\n","Row1  Row1/Col1  Row1/Col2  Row1/Col3  Row1/Col4\n","Row2  Row2/Col1  Row2/Col2  Row2/Col3  Row2/Col4\n","Row3  Row3/Col1  Row3/Col2  Row3/Col3  Row3/Col4"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Question 0: Create a DataFrame with three rows and four columns. Name the \n","# columns 'Col1', 'Col2', 'Col3', 'Col4'. Create an index for the DataFrame\n","# and give the rows the index values of 'Row1', 'Row2', 'Row3'. Place a value\n","# in each column equal to the {ColumnName/RowName}. e.g. Col1/Row1. Print\n","# the entire DataFrame.\n","\n","import pandas as pd\n","\n","df = pd.DataFrame(columns=['Col1', 'Col2', 'Col3', 'Col4'], index=['Row1', 'Row2', 'Row3'])\n","\n","for col in df:\n","  for i, value in df[col].items():\n","    df.at[i, col] = f'{i}/{col}'\n","\n","df"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":572},"executionInfo":{"elapsed":190,"status":"error","timestamp":1643600983401,"user":{"displayName":"Chris Dixon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgtFDbAKdsH3rRuFGe55dosyBvJnYTlTdmKPqLA=s64","userId":"01364049458282843424"},"user_tz":420},"id":"GlaDXTIXmMRc","outputId":"51d1c6f1-88b1-46ed-bc3e-5e4cf58925a4"},"outputs":[{"data":{"text/plain":["534"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Question 1: Import the datafile tw_tweets_users_media_places.csv that was \n","# provided with this checkpoint. Set tweet_id as the index. Print the number \n","# of records in this dataset in the output. How many records are there?\n","\n","tweets_df = pd.read_csv('tw_tweets_users_media_places.csv', index_col='tweet_id')\n","\n","num_records = tweets_df.shape[0]\n","\n","num_records\n","\n","\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1636479799203,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"6cshHRGgnj-r","outputId":"11df9f97-91eb-4a1b-be4e-5d6e252a176f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['context_annotations_count', 'count_annotations', 'count_cashtags',\n","       'count_hashtags', 'count_mentions', 'count_urls', 'likes', 'quotes',\n","       'referenced_tweet_count', 'replies', 'retweets', 'followers_count',\n","       'following_count', 'tweet_count', 'listed_count', 'height', 'width'],\n","      dtype='object')\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>context_annotations_count</th>\n","      <th>count_annotations</th>\n","      <th>count_cashtags</th>\n","      <th>count_hashtags</th>\n","      <th>count_mentions</th>\n","      <th>count_urls</th>\n","      <th>likes</th>\n","      <th>quotes</th>\n","      <th>referenced_tweet_count</th>\n","      <th>replies</th>\n","      <th>retweets</th>\n","      <th>followers_count</th>\n","      <th>following_count</th>\n","      <th>tweet_count</th>\n","      <th>listed_count</th>\n","      <th>height</th>\n","      <th>width</th>\n","    </tr>\n","    <tr>\n","      <th>tweet_id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1440484799970304000</th>\n","      <td>1</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>14</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>2709</td>\n","      <td>4999</td>\n","      <td>96</td>\n","      <td>15</td>\n","      <td>405</td>\n","      <td>813</td>\n","    </tr>\n","    <tr>\n","      <th>1439618825171963904</th>\n","      <td>2</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>140</td>\n","      <td>735</td>\n","      <td>99</td>\n","      <td>0</td>\n","      <td>2048</td>\n","      <td>1536</td>\n","    </tr>\n","    <tr>\n","      <th>1248872872837332992</th>\n","      <td>3</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>49</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>20</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>288</td>\n","      <td>278</td>\n","    </tr>\n","    <tr>\n","      <th>1250729294051053568</th>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>2048</td>\n","      <td>2048</td>\n","    </tr>\n","    <tr>\n","      <th>1249612131433095168</th>\n","      <td>1</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>2.0</td>\n","      <td>15</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>21</td>\n","      <td>7510</td>\n","      <td>7260</td>\n","      <td>100</td>\n","      <td>103</td>\n","      <td>2048</td>\n","      <td>2048</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     context_annotations_count  count_annotations  \\\n","tweet_id                                                            \n","1440484799970304000                          1                0.0   \n","1439618825171963904                          2                2.0   \n","1248872872837332992                          3                0.0   \n","1250729294051053568                          1                2.0   \n","1249612131433095168                          1                2.0   \n","\n","                     count_cashtags  count_hashtags  count_mentions  \\\n","tweet_id                                                              \n","1440484799970304000             0.0             0.0             0.0   \n","1439618825171963904             0.0             3.0             0.0   \n","1248872872837332992             0.0             0.0             0.0   \n","1250729294051053568             0.0             3.0             0.0   \n","1249612131433095168             0.0             3.0             0.0   \n","\n","                     count_urls  likes  quotes  referenced_tweet_count  \\\n","tweet_id                                                                 \n","1440484799970304000         1.0     14       0                       0   \n","1439618825171963904         1.0      7       0                       0   \n","1248872872837332992         1.0     49       1                       0   \n","1250729294051053568         2.0      3       0                       0   \n","1249612131433095168         2.0     15       2                       0   \n","\n","                     replies  retweets  followers_count  following_count  \\\n","tweet_id                                                                   \n","1440484799970304000        8         0             2709             4999   \n","1439618825171963904        0         0              140              735   \n","1248872872837332992        0        20             7510             7260   \n","1250729294051053568        0         1             7510             7260   \n","1249612131433095168        0        21             7510             7260   \n","\n","                     tweet_count  listed_count  height  width  \n","tweet_id                                                       \n","1440484799970304000           96            15     405    813  \n","1439618825171963904           99             0    2048   1536  \n","1248872872837332992          100           103     288    278  \n","1250729294051053568          100           103    2048   2048  \n","1249612131433095168          100           103    2048   2048  "]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Question 2: Make a copy of the DataFrame with all non-numeric features\n","# removed. Print out a list of the remaining columns in the output. Print\n","# the first five records of this reduced dataset.\n","numeric_df = tweets_df.select_dtypes(include='number')\n","print(numeric_df.columns)\n","\n","numeric_df.head()\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1475,"status":"ok","timestamp":1636479802849,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"FlptvGIhoMkd","outputId":"ab4250ad-bfb4-41db-a5d4-4ca4a02ab260"},"outputs":[{"name":"stdout","output_type":"stream","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:               retweets   R-squared:                       0.076\n","Model:                            OLS   Adj. R-squared:                  0.055\n","Method:                 Least Squares   F-statistic:                     3.578\n","Date:                Sat, 10 Feb 2024   Prob (F-statistic):           3.81e-05\n","Time:                        11:19:20   Log-Likelihood:                -2328.2\n","No. Observations:                 534   AIC:                             4682.\n","Df Residuals:                     521   BIC:                             4738.\n","Df Model:                          12                                         \n","Covariance Type:            nonrobust                                         \n","=============================================================================================\n","                                coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------------------\n","const                         7.5086      3.530      2.127      0.034       0.574      14.443\n","context_annotations_count     0.0735      0.265      0.278      0.781      -0.447       0.594\n","count_annotations            -1.0806      0.910     -1.187      0.236      -2.869       0.708\n","count_cashtags               -2.1163      9.654     -0.219      0.827     -21.081      16.849\n","count_hashtags               -0.2302      0.185     -1.244      0.214      -0.594       0.133\n","count_mentions            -1.091e-13   7.31e-14     -1.493      0.136   -2.53e-13    3.45e-14\n","count_urls                   -2.8647      2.167     -1.322      0.187      -7.122       1.393\n","referenced_tweet_count       -2.8994      2.869     -1.011      0.313      -8.536       2.737\n","followers_count            6.438e-05   6.09e-05      1.057      0.291   -5.53e-05       0.000\n","following_count              -0.0001      0.000     -1.000      0.318      -0.000       0.000\n","tweet_count               -7.389e-05   6.95e-05     -1.063      0.288      -0.000    6.27e-05\n","listed_count                  0.0036      0.009      0.379      0.705      -0.015       0.022\n","height                       -0.0030      0.002     -1.508      0.132      -0.007       0.001\n","width                         0.0041      0.002      1.794      0.073      -0.000       0.009\n","==============================================================================\n","Omnibus:                     1027.647   Durbin-Watson:                   2.024\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):           928034.759\n","Skew:                          13.163   Prob(JB):                         0.00\n","Kurtosis:                     205.525   Cond. No.                     1.63e+21\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 6.94e-31. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n"]}],"source":["# Question 3: Using 'retweets' as the label, create an MLR model using all\n","# features except 'likes', 'quotes', 'replies', and the label. These features\n","# each represent outcomes, or alternatives to the label 'rewteets.' If our\n","# plan is to use this model to predict the popularity of new potential tweets,\n","# then we would not know what the likes, quotes, or replies will be. Therefore,\n","# we will eliminate them from the model. Print out the model results summary.\n","\n","import statsmodels.api as sm\n","\n","# Assuming 'tweets_df' is your DataFrame\n","\n","# Selecting the label\n","y = numeric_df['retweets']\n","\n","# Selecting the features, excluding 'likes', 'quotes', 'replies', and 'retweets'\n","X = numeric_df.drop(['retweets', 'likes', 'quotes', 'replies'], axis=1)\n","\n","# Adding a constant to the model (intercept)\n","X = sm.add_constant(X)\n","\n","# Create the MLR model\n","model = sm.OLS(y, X)\n","\n","# Fit the model\n","results = model.fit()\n","\n","# Print out the summary of the model\n","print(results.summary())"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"elapsed":138,"status":"ok","timestamp":1636479806420,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"IylebrYzECmY","outputId":"6f45564c-0daa-4b28-d39d-efc86bc8d2e3"},"outputs":[],"source":["# Question 4: Add the scored (i.e. predicted) values for every record \n","# back into the original dataframe using the column label \"model_1\". Print\n","# the first five records.\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125,"status":"ok","timestamp":1636479808497,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"_6xVmDFzECt7","outputId":"f5869d60-9a90-43e0-f00d-dab936882d2d"},"outputs":[],"source":["# Question 5: Calculate and/or print the following five metrics for the \n","# model you ran in the prior steps: R-squared, R-squared adjusted, RMSE, \n","# MAE, and mean of the label column. \n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":476},"executionInfo":{"elapsed":137,"status":"ok","timestamp":1636479810399,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"0TTrsvDGGv7H","outputId":"467048a9-0a71-4613-cbe9-870ceeddf8d3"},"outputs":[],"source":["# Question 6: We need to improve the model fit so that our predictions will\n","# be more accurate. Let's begin by incorporating the two date columns from\n","# the original dataset. Convert the features 'created_at_tweet' and \n","# 'created_at_author' to an integer representing the number of days since\n","# those dates until January 1st, 2022. Do not put these values into new \n","# columns. Replace the existing dates with those values. \n","\n","# HINT: First, cast those columns to dt.date data types. Second, there are\n","# many ways to calculate the number of days until January 1, 2022. But I \n","# used the strptime() method of the datetime package to cast \"2022-1-1\" \n","# into a date, subtract the column value from that date, and then return \n","# the result in days (.dt.days). \n","\n","# Print the first five records of this new dataset.\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125,"status":"ok","timestamp":1636479813016,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"8JMgz_Mvp9T1","outputId":"48fdd320-4fa1-441d-f61f-ad29687e9cfa"},"outputs":[],"source":["# Question 7: Create another model that includes these two new columns\n","# representing the number of days since Jan 1, 2022. As before, eliminate\n","# all remaining non-numeric features and the other label candidates 'likes',\n","# 'quotes', and 'replies'. \n","\n","# Print out the results summary.\n","\n","# HINT: Do not forget that if you are using the same DataFrame that contained\n","# the 'model_1' predicted values column, you will need to drop that column as \n","# well. Otherwise, you are creating a new model to predict retweet count using\n","# a predicted value of retweet count from a prior model run which doesn't make\n","# any sense. However, you may have created a copy of the DataFrame in some \n","# prior task so that 'model_1' is not even in the DataFrame you are using now. \n","# In that case, this HINT is irrelevant.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125,"status":"ok","timestamp":1636479817156,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"0csUGODhSl5F","outputId":"2675aa94-fce6-4632-abb3-fcc1b461914e"},"outputs":[],"source":["# Question 8: Once again, print out the fit metrics--R-squared, R-squared-adjusted,\n","# RMSE, MAE--as well as the label mean for this revised model. \n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"elapsed":282,"status":"ok","timestamp":1636479819498,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"CFbKvKp2GRG2","outputId":"1afe9728-6fb8-4ad1-a6dc-a9cb50016b00"},"outputs":[],"source":["# Question 9: We want to improve model fit even further by generating \n","# dummy codes for some of the categorical features that do not have too many \n","# group values like 'text' and 'url' do. In particular, generate dummy \n","# codes for 'lang', 'reply_settings', 'source', 'protected', 'verified', and\n","# 'terms' and include them in the original dataframe. Remove all remaining \n","# non-numeric features as well as the alternative labels 'likes', 'quotes', \n","# and 'replies'. As in #7, make sure you are not including the 'model_1' \n","# column of predicted values. Do not train the model again yet. You are \n","# just creating the dummy codes in this step.\n","\n","# Print out the first five records after the dummy codes are created.\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126,"status":"ok","timestamp":1636479821548,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"LPQ83yIPWDx2","outputId":"183c832d-6e28-4ccf-e46c-e87db73fd0b4"},"outputs":[],"source":["# Question 10: Generate another model using all remaining numeric features\n","# along with these new dummy codes AND the days since dates features we \n","# created previously. Print out the results summary.\n","\n"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":910,"status":"ok","timestamp":1636479825725,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"tHa6oRPFZe67","outputId":"0971b0df-909a-40d6-ad7f-8c4c6b1ff52c"},"outputs":[],"source":["# Question 11: Now we have a fairly large number of features. But not all of\n","# them are significantly helping the model. Many of them have non-significant\n","# p-values or may be suffering from excessive multi-collinearity. Calculate\n","# the VIF score for each feature and add it to a new DataFrame. Sort the \n","# DataFrame from largest to smallest VIF score and display it in the output.\n","# HINT: There may be a function in the book to help you with this.\n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":138,"status":"ok","timestamp":1636479829880,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"FN00salHZl1G","outputId":"7659e31d-158c-44e8-933d-83948923b5a8"},"outputs":[],"source":["# Question 12: We need to eliminate those features with excessive multi-collinearity. \n","# However, this may happen naturally as we remove those features with large p-values. \n","# Therefore, start by removing the feature with the highest p-value and then rerun \n","# the prior model. One-at-a-time, continue removing the feature with the highest p-value \n","# (rerunning the model each time) until the difference between R-squared and R-squared\n","# adjusted is <= 0.01 (rounded). \n","\n","# Why would we do this? Because when R-squared adjusted is significantly lower than \n","# R-squared, we have too many variables in the model that are not significantly \n","# contributing to model fit. Once more, remove the highest p-value feature one-at-a-time\n","# until R-squared minus R-squared adjusted is <= 0.01 (rounded). You do NOT need to keep\n","# the results summary of every model. You can overwrite the prior model summary each time\n","# until you meet the criterion.\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1636479833828,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"-a_sOLPRdAho","outputId":"e7211009-76fc-4d39-9136-9e6fdc1be772"},"outputs":[],"source":["# Question 13: For the remaining features in the last model you produced\n","# where the difference between R2 and R2-adj is <= 0.01, calculate the VIF\n","# scores and print them out in a table from largest VIF to smallest.\n","\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"elapsed":275,"status":"ok","timestamp":1636479836773,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"o8m3hZLiZ0Yv","outputId":"af35bd53-6594-4cd8-90ac-ec46851ed531"},"outputs":[],"source":["# Question 14: Now we have a nice and trim model. However, we cannot \n","# compare the coefficients to each other since they are each on different\n","# scales. Therefore, use a Min-Max normalization to convert all features\n","# and label to the same scale. Print out the first five records.\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1636479839256,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"PEHSIQejc8jN","outputId":"2de81416-af87-427a-add4-4b085b3dd614"},"outputs":[],"source":["# Question 15: Rerun your last model using the normalized values. Print\n","# the results summary.\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"elapsed":1325,"status":"ok","timestamp":1636479844601,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"4jz1yihEeK4I","outputId":"53eae504-d4b8-4b45-f542-c947ec5fc268"},"outputs":[],"source":["# Question 16: Now that we have addressed multi-collinearity and have\n","# standardized the features, we should examine and address skewness. Print\n","# the skewness score for the label 'retweets'. In addition, use the .histplot()\n","# object from the seaborn package to print out a histogram of 'retweets'.\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"elapsed":1001,"status":"ok","timestamp":1636479847856,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"7kS4UZ7HgJrZ","outputId":"d3c17297-6579-4c9d-ed4b-77128afe1a6d"},"outputs":[],"source":["# Question 17: The skewness of retweets is clearly very extreme. However, we cannot \n","# create a natural log transformation since there are zero values (ln(0) = undefined).\n","# Therefore, we need to +1 to all values before we calculate the natural log. \n","# Thankfully, there is a numpy method for that: np.log1p(). Convert the 'retweets' \n","# label to a natural log +1. Print out the new skewness and histogram.\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141,"status":"ok","timestamp":1636479850576,"user":{"displayName":"Adam Mautz","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"05282401063904326318"},"user_tz":420},"id":"l18OC0kcfSV6","outputId":"6584554e-4a7b-4ee1-b571-4a00c44db1c6"},"outputs":[],"source":["# Question 18: Rerun the last MLR model using this new natural log +1 version\n","# of 'retweets'. Print out the results summary.\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Checkpoint_MLR_solution.ipynb","provenance":[]},"interpreter":{"hash":"ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"},"kernelspec":{"display_name":"Python 3.9.1 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
