{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path):\n",
    "  import pandas as pd, numpy as np\n",
    "  df = pd.read_csv(path)\n",
    "  # Artificially creating problems so that we can prepare for missing data\n",
    "  # Delete these four lines when the pipeline is ready\n",
    "  df = df.sample(n=2000, random_state=1)\n",
    "  df['missing'] = np.nan\n",
    "  df.iloc[2:5, 4] = np.nan\n",
    "  df.iloc[2:4, 2:6] = np.nan\n",
    "  df.iloc[0] = np.nan\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(df, label):\n",
    "  import pandas as pd\n",
    "  y = df[label]\n",
    "  X = df.drop(columns=[label])\n",
    "  return [y, X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_code(df):\n",
    "  import pandas as pd\n",
    "  df = pd.get_dummies(df, drop_first=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(df, label, row_thresh=0.90, col_thresh=0.70):\n",
    "  import pandas as pd, numpy as np\n",
    "\n",
    "  # Drop rows with the label missing\n",
    "  df.dropna(axis='rows', subset=[label], inplace=True)\n",
    "\n",
    "  # Drop rows and columns with 100% missing\n",
    "  df.dropna(axis='columns', thresh=1, inplace=True)\n",
    "  df.dropna(axis='rows', thresh=1, inplace=True)\n",
    "\n",
    "  # Drop rows with < threshold existing\n",
    "  df.dropna(axis='rows', thresh=round(df.shape[1]*row_thresh), inplace=True)\n",
    "\n",
    "  # Drop columns with < threshold existing\n",
    "  df.dropna(axis='columns', thresh=round(df.shape[0]*col_thresh), inplace=True)\n",
    "\n",
    "  # Impute remaining missing values\n",
    "  if df.isna().sum().sum() > 0:\n",
    "    from sklearn.experimental import enable_iterative_imputer\n",
    "    from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "    y, X = setup_model(df, label)\n",
    "    X = dummy_code(X)\n",
    "    imp = IterativeImputer(max_iter=10, random_state=1)\n",
    "    X = pd.DataFrame(imp.fit_transform(X), columns=X.columns, index=X.index)\n",
    "    df = X.merge(y, left_index=True, right_index=True)\n",
    "\n",
    "  # Return the cleaned DataFrame\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, label, random=\"False\"):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y, X = setup_model(df, label)\n",
    "    random_state = 1 \n",
    "    if random: random_state = 0\n",
    "    return train_test_split(X, y, test_size=.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(df, label, random = False, repeat= True):\n",
    "    from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
    "    from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "    import pandas as pd\n",
    "\n",
    "    y, X = setup_model(df, label)\n",
    "\n",
    "    random_state = 1\n",
    "    if random: random_state = 0\n",
    "\n",
    "    if repeat:\n",
    "        cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=random_state)\n",
    "    else:\n",
    "        cv = KFold(n_splits=5, random_state=random_state)\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(df[label]):\n",
    "        scores = cross_val_score(RandomForestRegressor(), X, y, scoring='r2', cv=cv)\n",
    "    else: \n",
    "        scores = cross_val_score(RandomForestClassifier(), X, y, scoring='accuracy', cv=cv)\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Step 1: Import the data\n",
    "df = import_data('network_traffic.csv')\n",
    "# Step 2: Data Preparation\n",
    "df = missing_data(df, 'attack',.92)\n",
    "\n",
    "# step 3A: Data Segregation Train/Test split\n",
    "X_train, X_test, y_train, y_test = split_data(df, 'attack')\n",
    "\n",
    "# step 3A: Data Segregation Cross Validation\n",
    "cross_validate(df, 'attack')\n",
    "\n",
    "print(X_train.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute or predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
