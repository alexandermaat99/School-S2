{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(path, n):\n",
    "  import pandas as pd, numpy as np\n",
    "  if n is None: n = df.shape[0]\n",
    "  df = pd.read_csv(path)\n",
    "  df = df.sample(n=n, random_state=1)\n",
    "  # Artificially creating problems so that we can prepare for missing data\n",
    "  # Delete these four lines when the pipeline is ready\n",
    "  df['missing'] = np.nan\n",
    "  df.iloc[2:5, 4] = np.nan\n",
    "  df.iloc[2:4, 2:6] = np.nan\n",
    "  df.iloc[0] = np.nan\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(df, label):\n",
    "  import pandas as pd\n",
    "  y = df[label]\n",
    "  X = df.drop(columns=[label])\n",
    "  return [y, X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_code(df):\n",
    "  import pandas as pd\n",
    "  df = pd.get_dummies(df, drop_first=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_data(df, label, row_thresh=0.90, col_thresh=0.70):\n",
    "  import pandas as pd, numpy as np\n",
    "\n",
    "  # Drop rows with the label missing\n",
    "  df.dropna(axis='rows', subset=[label], inplace=True)\n",
    "\n",
    "  # Drop rows and columns with 100% missing\n",
    "  df.dropna(axis='columns', thresh=1, inplace=True)\n",
    "  df.dropna(axis='rows', thresh=1, inplace=True)\n",
    "\n",
    "  # Drop rows with < threshold existing\n",
    "  df.dropna(axis='rows', thresh=round(df.shape[1]*row_thresh), inplace=True)\n",
    "\n",
    "  # Drop columns with < threshold existing\n",
    "  df.dropna(axis='columns', thresh=round(df.shape[0]*col_thresh), inplace=True)\n",
    "\n",
    "  # Impute remaining missing values\n",
    "  if df.isna().sum().sum() > 0:\n",
    "    from sklearn.experimental import enable_iterative_imputer\n",
    "    from sklearn.impute import IterativeImputer, KNNImputer\n",
    "\n",
    "    y, X = setup_model(df, label)\n",
    "    X = dummy_code(X)\n",
    "    imp = IterativeImputer(max_iter=10, random_state=1)\n",
    "    X = pd.DataFrame(imp.fit_transform(X), columns=X.columns, index=X.index)\n",
    "    df = X.merge(y, left_index=True, right_index=True)\n",
    "\n",
    "  # Return the cleaned DataFrame\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_categories(df, features=[], cutoff=0.05, replace_with='Other', messages=True):\n",
    "  import pandas as pd\n",
    "  \n",
    "  if len(features) == 0: features = df.columns\n",
    "\n",
    "  for feat in features:\n",
    "    if feat in df.columns:\n",
    "      if not pd.api.types.is_numeric_dtype(df[feat]):\n",
    "        other_list = df[feat].value_counts()[df[feat].value_counts() / df.shape[0] < cutoff].index\n",
    "        df.loc[df[feat].isin(other_list), feat] = replace_with\n",
    "        if messages: print(f'{feat} has been binned by setting {other_list} to {replace_with}')\n",
    "    else:\n",
    "      if messages: print(f'{feat} not found in the DataFrame provided. No binning performed')\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //split data and cross validation are optional\n",
    "\n",
    "def split_data(df, label, random=\"False\"):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    y, X = setup_model(df, label)\n",
    "    random_state = 1 \n",
    "    if random: random_state = 0\n",
    "    return train_test_split(X, y, test_size=.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(df, label, k=5, random=False, repeat=True):\n",
    "  from sklearn.model_selection import KFold, RepeatedKFold, cross_val_score\n",
    "  import pandas as pd\n",
    "  from numpy import mean\n",
    "\n",
    "  y, X = setup_model(df, label)\n",
    "\n",
    "  random_state=1\n",
    "  if random: random_state=0\n",
    "\n",
    "  if repeat:\n",
    "    cv = RepeatedKFold(n_splits=k, n_repeats=5, random_state=random_state)\n",
    "  else:\n",
    "    cv = KFold(n_splits=k, random_state=random_state, shuffle=True)\n",
    "\n",
    "  if pd.api.types.is_numeric_dtype(df[label]):\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    scores = cross_val_score(RandomForestRegressor(), X, y, scoring='r2', cv=cv)\n",
    "  else:\n",
    "    from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "    from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "\n",
    "    model_rfc = RandomForestClassifier(random_state=random_state)\n",
    "    model_gbc = GradientBoostingClassifier(random_state=random_state)\n",
    "    model_log = LogisticRegression(random_state=random_state, max_iter=100)\n",
    "    model_ridge = RidgeClassifier(random_state=random_state)\n",
    "\n",
    "    scores_rfc = cross_val_score(model_rfc, X, y, scoring='accuracy', cv=cv)\n",
    "    scores_gbc = cross_val_score(model_gbc, X, y, scoring='accuracy', cv=cv)\n",
    "    scores_log = cross_val_score(model_log, X, y, scoring='accuracy', cv=cv)\n",
    "    scores_ridge = cross_val_score(model_ridge, X, y, scoring='accuracy', cv=cv)\n",
    "\n",
    "    models = {mean(scores_rfc):model_rfc, mean(scores_gbc):model_gbc, mean(scores_log):model_log, mean(scores_ridge):model_ridge}\n",
    "\n",
    "    print(f'Accuracy (RandomForest):\\t{mean(scores_rfc)}')\n",
    "    print(f'Accuracy (GradientBoosting):\\t{mean(scores_gbc)}')\n",
    "    print(f'Accuracy (Ridge):\\t\\t{mean(scores_log)}')\n",
    "    print(f'Accuracy (Logistic):\\t\\t{mean(scores_ridge)}')\n",
    "\n",
    "    return models[max(models.keys())].fit(X, y)\n",
    "\n",
    "\n",
    "    #  want the best balance of accuracy and speed\n",
    "    #  lowest result is the best result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_name):\n",
    "    import pickle \n",
    "    pickle.dump(model, open(file_name, 'wb'))\n",
    "\n",
    "def load_model(file_name):\n",
    "    import pickle\n",
    "    return pickle.load(open(file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'max_iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 24\u001b[0m\n\u001b[0;32m     10\u001b[0m df_5 \u001b[38;5;241m=\u001b[39m bin_categories(df\u001b[38;5;241m.\u001b[39mcopy(), cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# df_2 = bin_categories(df.copy(), cutoff=0.02)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# df_1 = bin_categories(df.copy(), cutoff=0.01)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#  want the best balance of accuracy and speed\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#  lowest result is the best result \u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#builds 5 models - probably the best one \u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# cross_validate(df_2, 'attack', 5, repeat=False) #builds 5 models - probably the best one \u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# cross_validate(df_1, 'attack', 5, repeat=False) #builds 5 models - probably the best one \u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# df.head()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[100], line 23\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(df, label, k, random, repeat)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, GradientBoostingClassifier\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RidgeClassifier, LogisticRegression\n\u001b[1;32m---> 23\u001b[0m model_rfc \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m model_gbc \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m     25\u001b[0m model_log \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39mrandom_state, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomForestClassifier.__init__() got an unexpected keyword argument 'max_iter'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Step 1: Import the data\n",
    "df = import_data('network_traffic.csv', n=df.shape[0])\n",
    "# Step 2: Data Preparation\n",
    "df = missing_data(df, 'attack',.92)\n",
    "\n",
    "# step 3A: Data Segregation Train/Test split\n",
    "# X_train, X_test, y_train, y_test = split_data(df, 'attack')\n",
    "df_5 = bin_categories(df.copy(), cutoff=0.05, messages=False)\n",
    "# df_2 = bin_categories(df.copy(), cutoff=0.02)\n",
    "# df_1 = bin_categories(df.copy(), cutoff=0.01)\n",
    "\n",
    "\n",
    "# step 3A: Data Segregation Cross Validation\n",
    "# cross_validate(df, 'attack', 5, repeat=False) #builds 5 models - probably the best one \n",
    "# cross_validate(df, 'attack', 10, repeat=False) #builds 10 models\n",
    "# cross_validate(df, 'attack', 5, repeat=True) #builds 25 modles \n",
    "# cross_validate(df, 'attack', 10, repeat=True) #builds 50 models\n",
    "\n",
    "#  want the best balance of accuracy and speed\n",
    "#  lowest result is the best result \n",
    "\n",
    "cross_validate(df_5, 'attack', 5, repeat=False) #builds 5 models - probably the best one \n",
    "# cross_validate(df_2, 'attack', 5, repeat=False) #builds 5 models - probably the best one \n",
    "# cross_validate(df_1, 'attack', 5, repeat=False) #builds 5 models - probably the best one \n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "RandomForestClassifier.__init__() got an unexpected keyword argument 'max_itter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m bin_categories(df\u001b[38;5;241m.\u001b[39mcopy(), cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, messages\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Step 3: Data Segregation: Crossvalidate\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepeat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Step 4: Save/Deploy the trained model\u001b[39;00m\n\u001b[0;32m     11\u001b[0m save_model(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_model.sav\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[81], line 23\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(df, label, k, random, repeat)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier, GradientBoostingClassifier\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RidgeClassifier, LogisticRegression\n\u001b[1;32m---> 23\u001b[0m model_rfc \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_itter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m model_gbc \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m     25\u001b[0m model_log \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39mrandom_state, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: RandomForestClassifier.__init__() got an unexpected keyword argument 'max_itter'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Step 1: Import the data\n",
    "df = import_data('network_traffic.csv', n=df.shape[0])\n",
    "# Step 2: Data Preparation\n",
    "df = missing_data(df, 'attack',.92)\n",
    "df = bin_categories(df.copy(), cutoff=0.05, messages=False)\n",
    "# Step 3: Data Segregation: Crossvalidate\n",
    "model = cross_validate(df, 'attack', 5, repeat=False)\n",
    "# Step 4: Save/Deploy the trained model\n",
    "save_model(model, 'saved_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute or predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
