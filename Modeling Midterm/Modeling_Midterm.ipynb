{"cells":[{"cell_type":"markdown","metadata":{"id":"f_QvT540iPPK"},"source":["### READ ME\n","\n","Use the code blocks below to answer each quiz question. Only print the output required for each question. Do not edit the comments at the top of each code cell. Otherwise, the auto-grader may misinterpret your results. See Question 0 as an an example of how to complete a task (leave it in your notebook; don't delete it):"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"0IQdvphwiIQq","outputId":"c9d19b58-119d-463a-afe8-77ddbe656dd3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Col1</th>\n","      <th>Col2</th>\n","      <th>Col3</th>\n","      <th>Col4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Row1</th>\n","      <td>Row1/Col1</td>\n","      <td>Row1/Col2</td>\n","      <td>Row1/Col3</td>\n","      <td>Row1/Col4</td>\n","    </tr>\n","    <tr>\n","      <th>Row2</th>\n","      <td>Row2/Col1</td>\n","      <td>Row2/Col2</td>\n","      <td>Row2/Col3</td>\n","      <td>Row2/Col4</td>\n","    </tr>\n","    <tr>\n","      <th>Row3</th>\n","      <td>Row3/Col1</td>\n","      <td>Row3/Col2</td>\n","      <td>Row3/Col3</td>\n","      <td>Row3/Col4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           Col1       Col2       Col3       Col4\n","Row1  Row1/Col1  Row1/Col2  Row1/Col3  Row1/Col4\n","Row2  Row2/Col1  Row2/Col2  Row2/Col3  Row2/Col4\n","Row3  Row3/Col1  Row3/Col2  Row3/Col3  Row3/Col4"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["# Question 0: Create a DataFrame with three rows and four columns. Name the \n","# columns 'Col1', 'Col2', 'Col3', 'Col4'. Create an index for the DataFrame\n","# and give the rows the index values of 'Row1', 'Row2', 'Row3'. Place a value\n","# in each column equal to the {ColumnName/RowName}. e.g. Col1/Row1. Print\n","# the entire DataFrame.\n","\n","import pandas as pd\n","\n","df = pd.DataFrame(columns=['Col1', 'Col2', 'Col3', 'Col4'], index=['Row1', 'Row2', 'Row3'])\n","\n","for col in df:\n","  for i, value in df[col].items():\n","    df.at[i, col] = f'{i}/{col}'\n","\n","df"]},{"cell_type":"markdown","metadata":{"id":"IFFefjks0RJx"},"source":["### Regression Questions\n","\n","The conceptual questions (which do not require coding) are skipped in this notebook"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"ntk3B1kaiSsK"},"outputs":[],"source":["# Question 1: Conceptual question; answer in MyEducator. Nothing to do here"]},{"cell_type":"code","execution_count":75,"metadata":{"id":"ynNI4Vi-ieh6"},"outputs":[],"source":["# Question 2: Conceptual question; answer in MyEducator. Nothing to do here"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"vgx5H_uVieke"},"outputs":[],"source":["# Question 3: Conceptual question; answer in MyEducator. Nothing to do here"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"Xb7Fscp30RJ4"},"outputs":[],"source":["# Question 4: Conceptual question; answer in MyEducator. Nothing to do here "]},{"cell_type":"code","execution_count":78,"metadata":{"id":"XZKfK2YX0RJ6"},"outputs":[],"source":["# Question 5: Conceptual question; answer in MyEducator. Nothing to do here"]},{"cell_type":"code","execution_count":79,"metadata":{"id":"X03_eih40RJ9"},"outputs":[{"data":{"text/plain":["gender                         object\n","race/ethnicity                 object\n","parental level of education    object\n","lunch                          object\n","test preparation course        object\n","math score                      int64\n","reading score                   int64\n","writing score                   int64\n","dtype: object"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["# Question 6: Download the StudentsPerformance.csv dataset that is provided with this exam. Import it into a DataFrame. Print a list of column names and their associated data types. Which columns would make sense to predict as a label in an MLR?\n","df = pd.read_csv('StudentsPerformance.csv')\n","df.dtypes"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"2_KUGZvR0RKA"},"outputs":[{"name":"stdout","output_type":"stream","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:             math score   R-squared:                       0.674\n","Model:                            OLS   Adj. R-squared:                  0.673\n","Method:                 Least Squares   F-statistic:                     1031.\n","Date:                Sat, 23 Mar 2024   Prob (F-statistic):          2.25e-243\n","Time:                        14:24:52   Log-Likelihood:                -3576.9\n","No. Observations:                1000   AIC:                             7160.\n","Df Residuals:                     997   BIC:                             7175.\n","Df Model:                           2                                         \n","Covariance Type:            nonrobust                                         \n","=================================================================================\n","                    coef    std err          t      P>|t|      [0.025      0.975]\n","---------------------------------------------------------------------------------\n","const             7.5241      1.328      5.665      0.000       4.918      10.131\n","reading score     0.6013      0.063      9.538      0.000       0.478       0.725\n","writing score     0.2494      0.061      4.118      0.000       0.131       0.368\n","==============================================================================\n","Omnibus:                       10.227   Durbin-Watson:                   2.087\n","Prob(Omnibus):                  0.006   Jarque-Bera (JB):                6.801\n","Skew:                           0.006   Prob(JB):                       0.0334\n","Kurtosis:                       2.596   Cond. No.                         481.\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"]}],"source":["# Question 7: Drop any rows that contain null values in any column using .dropna(). Use the statsmodels package to create an MLR/OLS model to predict math score as a function of the reading score and writing score. Do not split the data; use the entire dataset for training. Allow the y-intercept to vary.\n","\n","# Which feature best predicts their math score?\n","\n","df = df.dropna()\n","import statsmodels.api as sm\n","\n","label = \"math score\"\n","\n","y=df[label]\n","X=df[['reading score', 'writing score']]\n","\n","model = sm.OLS(y, sm.add_constant(X)).fit()\n","print(model.summary())\n","\n","\n"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"OCD4riSq0RKE"},"outputs":[{"name":"stdout","output_type":"stream","text":["                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:             math score   R-squared:                       0.255\n","Model:                            OLS   Adj. R-squared:                  0.246\n","Method:                 Least Squares   F-statistic:                     28.12\n","Date:                Sat, 23 Mar 2024   Prob (F-statistic):           2.62e-55\n","Time:                        14:24:52   Log-Likelihood:                -3990.3\n","No. Observations:                1000   AIC:                             8007.\n","Df Residuals:                     987   BIC:                             8070.\n","Df Model:                          12                                         \n","Covariance Type:            nonrobust                                         \n","==================================================================================================================\n","                                                     coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------------------------------------------\n","const                                             23.0302      0.187    123.319      0.000      22.664      23.397\n","gender_female                                      9.0175      0.428     21.083      0.000       8.178       9.857\n","gender_male                                       14.0128      0.432     32.452      0.000      13.165      14.860\n","race/ethnicity_group A                             0.6087      1.195      0.509      0.611      -1.736       2.953\n","race/ethnicity_group B                             2.6495      0.875      3.028      0.003       0.932       4.367\n","race/ethnicity_group C                             3.0787      0.728      4.229      0.000       1.650       4.507\n","race/ethnicity_group D                             5.9498      0.779      7.639      0.000       4.421       7.478\n","race/ethnicity_group E                            10.7435      0.988     10.869      0.000       8.804      12.683\n","parental level of education_associate's degree     4.6350      0.857      5.409      0.000       2.953       6.317\n","parental level of education_bachelor's degree      6.6011      1.097      6.019      0.000       4.449       8.753\n","parental level of education_high school           -0.1678      0.902     -0.186      0.852      -1.938       1.602\n","parental level of education_master's degree        7.5234      1.495      5.033      0.000       4.590      10.457\n","parental level of education_some college           4.0523      0.849      4.772      0.000       2.386       5.719\n","parental level of education_some high school       0.3863      0.932      0.414      0.679      -1.443       2.216\n","lunch_free/reduced                                 6.0767      0.466     13.049      0.000       5.163       6.991\n","lunch_standard                                    16.9535      0.426     39.805      0.000      16.118      17.789\n","test preparation course_completed                 14.2624      0.467     30.533      0.000      13.346      15.179\n","test preparation course_none                       8.7678      0.427     20.518      0.000       7.929       9.606\n","==============================================================================\n","Omnibus:                        9.026   Durbin-Watson:                   2.043\n","Prob(Omnibus):                  0.011   Jarque-Bera (JB):                9.201\n","Skew:                          -0.232   Prob(JB):                       0.0100\n","Kurtosis:                       2.928   Cond. No.                     1.35e+16\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 1.67e-29. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n"]}],"source":["# Question 8: In the original DataFrame convert each of the non-numeric features into dummy codes. Generate an OLS/MLR model (using the statsmodels package) to predict math score. However, do not include either reading score or writing score as features; only include those dummy codes created from the categorical features. Do not split the data; use the entire dataset for training. Print the results summary.\n","\n","# Do test preparation courses improve math scores?\n","\n","dummies = df.select_dtypes(['object']).columns  # Creates a list of column names that are 'object' dtype\n","df = pd.get_dummies(df, columns=dummies)\n","\n","df = df*1\n","\n","label = \"math score\"\n","y=df[label]\n","X=df.drop(columns=[label, 'reading score', 'writing score'])\n","\n","model = sm.OLS(y, sm.add_constant(X)).fit()\n","print(model.summary())\n","\n","\n","\n"]},{"cell_type":"code","execution_count":105,"metadata":{"id":"fKd3_bR90RKX"},"outputs":[{"name":"stdout","output_type":"stream","text":["Writing Score Model Summary:\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:          writing score   R-squared:                       0.334\n","Model:                            OLS   Adj. R-squared:                  0.326\n","Method:                 Least Squares   F-statistic:                     41.25\n","Date:                Sat, 23 Mar 2024   Prob (F-statistic):           8.17e-79\n","Time:                        15:15:46   Log-Likelihood:                -3936.2\n","No. Observations:                1000   AIC:                             7898.\n","Df Residuals:                     987   BIC:                             7962.\n","Df Model:                          12                                         \n","Covariance Type:            nonrobust                                         \n","==================================================================================================================\n","                                                     coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------------------------------------------\n","const                                             24.0046      0.177    135.676      0.000      23.657      24.352\n","gender_female                                     16.5506      0.405     40.845      0.000      15.755      17.346\n","gender_male                                        7.4541      0.409     18.222      0.000       6.651       8.257\n","race/ethnicity_group A                             1.8608      1.132      1.644      0.101      -0.360       4.082\n","race/ethnicity_group B                             3.0809      0.829      3.716      0.000       1.454       4.708\n","race/ethnicity_group C                             4.2734      0.690      6.196      0.000       2.920       5.627\n","race/ethnicity_group D                             7.7915      0.738     10.559      0.000       6.344       9.239\n","race/ethnicity_group E                             6.9981      0.936      7.473      0.000       5.160       8.836\n","parental level of education_associate's degree     4.5656      0.812      5.624      0.000       2.973       6.159\n","parental level of education_bachelor's degree      8.0505      1.039      7.749      0.000       6.012      10.089\n","parental level of education_high school           -1.2488      0.854     -1.462      0.144      -2.925       0.428\n","parental level of education_master's degree        9.7488      1.416      6.884      0.000       6.970      12.528\n","parental level of education_some college           3.6451      0.804      4.531      0.000       2.066       5.224\n","parental level of education_some high school      -0.7566      0.883     -0.857      0.392      -2.490       0.976\n","lunch_free/reduced                                 7.9009      0.441     17.909      0.000       7.035       8.767\n","lunch_standard                                    16.1037      0.404     39.910      0.000      15.312      16.896\n","test preparation course_completed                 17.0317      0.443     38.486      0.000      16.163      17.900\n","test preparation course_none                       6.9730      0.405     17.224      0.000       6.179       7.767\n","==============================================================================\n","Omnibus:                       16.647   Durbin-Watson:                   2.038\n","Prob(Omnibus):                  0.000   Jarque-Bera (JB):               17.222\n","Skew:                          -0.321   Prob(JB):                     0.000182\n","Kurtosis:                       2.982   Cond. No.                     1.35e+16\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 1.67e-29. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n","\n","Reading Score Model Summary:\n","                            OLS Regression Results                            \n","==============================================================================\n","Dep. Variable:          reading score   R-squared:                       0.227\n","Model:                            OLS   Adj. R-squared:                  0.218\n","Method:                 Least Squares   F-statistic:                     24.19\n","Date:                Sat, 23 Mar 2024   Prob (F-statistic):           8.62e-48\n","Time:                        15:15:46   Log-Likelihood:                -3970.5\n","No. Observations:                1000   AIC:                             7967.\n","Df Residuals:                     987   BIC:                             8031.\n","Df Model:                          12                                         \n","Covariance Type:            nonrobust                                         \n","==================================================================================================================\n","                                                     coef    std err          t      P>|t|      [0.025      0.975]\n","------------------------------------------------------------------------------------------------------------------\n","const                                             24.3079      0.183    132.753      0.000      23.949      24.667\n","gender_female                                     15.6897      0.419     37.413      0.000      14.867      16.513\n","gender_male                                        8.6183      0.423     20.357      0.000       7.787       9.449\n","race/ethnicity_group A                             2.2178      1.171      1.893      0.059      -0.081       4.517\n","race/ethnicity_group B                             3.5438      0.858      4.130      0.000       1.860       5.228\n","race/ethnicity_group C                             4.4917      0.714      6.293      0.000       3.091       5.892\n","race/ethnicity_group D                             6.3234      0.764      8.281      0.000       4.825       7.822\n","race/ethnicity_group E                             7.7313      0.969      7.977      0.000       5.829       9.633\n","parental level of education_associate's degree     4.6960      0.840      5.589      0.000       3.047       6.345\n","parental level of education_bachelor's degree      6.8519      1.075      6.373      0.000       4.742       8.962\n","parental level of education_high school           -0.2044      0.884     -0.231      0.817      -1.940       1.531\n","parental level of education_master's degree        8.9010      1.466      6.073      0.000       6.025      11.777\n","parental level of education_some college           3.4165      0.833      4.104      0.000       1.783       5.050\n","parental level of education_some high school       0.6469      0.914      0.708      0.479      -1.147       2.441\n","lunch_free/reduced                                 8.5311      0.457     18.684      0.000       7.635       9.427\n","lunch_standard                                    15.7769      0.418     37.780      0.000      14.957      16.596\n","test preparation course_completed                 15.8352      0.458     34.575      0.000      14.936      16.734\n","test preparation course_none                       8.4727      0.419     20.222      0.000       7.651       9.295\n","==============================================================================\n","Omnibus:                       11.191   Durbin-Watson:                   2.038\n","Prob(Omnibus):                  0.004   Jarque-Bera (JB):               11.258\n","Skew:                          -0.242   Prob(JB):                      0.00359\n","Kurtosis:                       2.812   Cond. No.                     1.35e+16\n","==============================================================================\n","\n","Notes:\n","[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n","[2] The smallest eigenvalue is 1.67e-29. This might indicate that there are\n","strong multicollinearity problems or that the design matrix is singular.\n","\n","Writing score is most accurately predicted.\n"]}],"source":["# Question 9: Generate OLS/MLR models to predict writing scores and reading scores using the same set of features. Similarly, drop the other two score features from each score model you create. For example, predict reading score, but do not include math score or writing score as features. Do not split the data; use the entire dataset for training. Print the results of each model summary. \n","\n","# Which score (reading, writing, or math) is most accurately predicted?\n","\n","# Model to predict writing score\n","y_writing = df['writing score']\n","X_writing = df.drop(columns=['math score', 'reading score', 'writing score'])\n","X_writing = sm.add_constant(X_writing)\n","model_writing = sm.OLS(y_writing, X_writing).fit()\n","print(\"Writing Score Model Summary:\")\n","print(model_writing.summary())\n","\n","# Model to predict reading score\n","y_reading = df['reading score']\n","X_reading = df.drop(columns=['math score', 'reading score', 'writing score'])\n","X_reading = sm.add_constant(X_reading)\n","model_reading = sm.OLS(y_reading, X_reading).fit()\n","print(\"\\nReading Score Model Summary:\")\n","print(model_reading.summary())\n","\n","# Compare R-squared values to determine the most accurately predicted score\n","r2_math = model.rsquared       # Assuming 'model' is your math score model\n","r2_writing = model_writing.rsquared\n","r2_reading = model_reading.rsquared\n","\n","# Determine the most accurately predicted score\n","if r2_math == max(r2_math, r2_writing, r2_reading):\n","    print(\"\\nMath score is most accurately predicted.\")\n","elif r2_writing == max(r2_math, r2_writing, r2_reading):\n","    print(\"\\nWriting score is most accurately predicted.\")\n","else:\n","    print(\"\\nReading score is most accurately predicted.\")\n","\n","\n"]},{"cell_type":"code","execution_count":108,"metadata":{"id":"EhN8xsRM0RKZ"},"outputs":[{"ename":"ValueError","evalue":"shapes (1,17) and (18,) not aligned: 17 (dim 1) != 18 (dim 0)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[108], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m input_data \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(input_data)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Predict the math score using the model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m predicted_math_score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Math Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predicted_math_score[\u001b[38;5;241m0\u001b[39m])\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\base\\model.py:1176\u001b[0m, in \u001b[0;36mResults.predict\u001b[1;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03mCall self.model.predict with self.params as the first argument.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;124;03mreturned prediction.\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1173\u001b[0m exog, exog_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_predict_exog(exog,\n\u001b[0;32m   1174\u001b[0m                                                 transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m-> 1176\u001b[0m predict_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[0;32m   1180\u001b[0m                                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predict_results\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\statsmodels\\regression\\linear_model.py:411\u001b[0m, in \u001b[0;36mRegressionModel.predict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog\n\u001b[1;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mValueError\u001b[0m: shapes (1,17) and (18,) not aligned: 17 (dim 1) != 18 (dim 0)"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Initialize input_data with zeros for all dummy variables\n","input_data = pd.DataFrame(np.zeros((1, len(model.params) - 1)), columns=model.params.index[1:])\n","\n","# Set the specific characteristics of the child\n","input_data['gender_female'] = 1\n","input_data['race/ethnicity_group C'] = 1\n","input_data['parental level of education_some college'] = 1\n","input_data['lunch_free/reduced'] = 1\n","input_data['test preparation course_none'] = 1\n","\n","# Ensure all other columns are set to 0 or appropriate default values\n","# (Here, we initially set all to 0, so no further action is required)\n","\n","# Add a constant to the input data\n","input_data = sm.add_constant(input_data)\n","\n","# Predict the math score using the model\n","predicted_math_score = model.predict(input_data)\n","\n","print(\"Predicted Math Score:\", predicted_math_score[0])\n"]},{"cell_type":"markdown","metadata":{"id":"CeYYgXv7A1PH"},"source":["### Classification\n"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"ynGlOCao0RKb"},"outputs":[],"source":["# Question 11: Conceptual question; answer in MyEducator. Nothing to do here"]},{"cell_type":"code","execution_count":85,"metadata":{"id":"1PgbUSxS0RKc"},"outputs":[],"source":["# Question 12: Conceptual question; answer in MyEducator. Nothing to do here"]},{"cell_type":"code","execution_count":86,"metadata":{"id":"kH5VpJXV0RKf"},"outputs":[],"source":["# Question 13: Conceptual question; answer in MyEducator. Nothing to do here"]},{"cell_type":"code","execution_count":87,"metadata":{"id":"6qCEm2yp0RKg"},"outputs":[],"source":["# Question 14: Conceptual question; answer in MyEducator. Nothing to do here"]},{"cell_type":"code","execution_count":88,"metadata":{"id":"Mx6FQnm2bGnr"},"outputs":[],"source":["#  Question 15: Import all needed packages for classification modeling, splitting the data, and calculating fit metrics. Import the Lending Club dataset found at: http://www.ishelp.info/data/lc_xs.csv. Alternatively, if the server is down, you can also download this data file from the MyEducator assignment description. \n","\n","# How many records are in the dataset?\n","\n"]},{"cell_type":"code","execution_count":89,"metadata":{"id":"fpCoW4JY0RKo"},"outputs":[],"source":["# Question 16: Run the code below. If you named your DataFrame something other than 'df', then be sure to change 'df' to whatever your DataFrame is named before running the code.\n","\n","# Based on the results, do you believe that Lending Club is doing a decent job of determining who will pay back their loans?\n","\n"]},{"cell_type":"code","execution_count":90,"metadata":{"id":"OHdNyAW2bXJa"},"outputs":[],"source":["# QUESTION 17: Drop the features: loan_status_numeric, issue_d, title, emp_title, emp_length, earliest_cr_line, mths_since_last_delinq, mths_since_last_record, sub_grade. Pseudocode:\n","#      df.drop(columns=[name, name, ..., name], inplace=True)\n","\n","# Since customers who are Current, In Grace Period, Late (16-30 days), and Late (31-120 days) have not finished their loan, drop all records except for those which are Fully Paid or Charged Off. Pseudocode: \n","#      df.loc[(df['column_name'] == A) | (df['column_name'] == B)]\n","\n","# Drop any rows containing null data using the command: df.dropna(inplace=True). \n","\n","# Finally, create dummy codes for all remaining categorical features (but not for the label loan_status)\n","\n","# Print out the first five records of the resulting DataFrame. How many columns are left after completing each of these tasks?\n","\n"]},{"cell_type":"code","execution_count":91,"metadata":{"id":"7ucdOAmEcIE2"},"outputs":[],"source":["# Question 18: Set the y and X datasets assuming that loan_status will be the label. Print the first 5 records of X\n"]},{"cell_type":"code","execution_count":92,"metadata":{"id":"dIlDfMhSc4t3"},"outputs":[],"source":["# Question 19: Split the data using a 50/50 split and random seed = 12345\n","\n","# Next, train a Decision Tree Classifier model using a random_state=12345 and fit the model with the appropriate data set\n","\n","# Print the Accuracy score using either the .accuracy_score() or .score() method of the Decision Tree Classifier model object. Be sure to pass in the appropriate data into those objects. What is that score? Copy and paste the entire number with all decimals included\n","\n"]},{"cell_type":"code","execution_count":93,"metadata":{"id":"JLH9qPrxdBzi"},"outputs":[],"source":["# Question 20: Predict the labels for test dataset and display them in a dataframe along with the actual values. Print only the LAST 10 records. Which row index was predicted incorrectly in these last 10 records? \n"]},{"cell_type":"markdown","metadata":{"id":"ki--_PWqA6je"},"source":["## Clustering\n"]},{"cell_type":"code","execution_count":94,"metadata":{"id":"xBrgRPZw0RKt"},"outputs":[],"source":["# Question 21: Conceptual question; answer in MyEducator. Nothing to do here."]},{"cell_type":"code","execution_count":95,"metadata":{"id":"x9uKVBWR0RKu"},"outputs":[],"source":["# Question 22: Conceptual question; answer in MyEducator. Nothing to do here."]},{"cell_type":"code","execution_count":96,"metadata":{"id":"My52iAlk0RKu"},"outputs":[],"source":["# Question 23: Conceptual question; answer in MyEducator. Nothing to do here."]},{"cell_type":"code","execution_count":97,"metadata":{"id":"vvXnd7iI0RKv"},"outputs":[],"source":["# Question 24: Conceptual question; answer in MyEducator. Nothing to do here."]},{"cell_type":"code","execution_count":98,"metadata":{"id":"G9uQNqPy0RKv"},"outputs":[],"source":["# Question 25: Conceptual question; answer in MyEducator. Nothing to do here."]},{"cell_type":"code","execution_count":99,"metadata":{"id":"ULizOdHpA8o7"},"outputs":[],"source":["# Question 26: Import the necessary libraries to perform your Clustering analysis. Once again, use the Lending Club dataset (lc_xs.csv) but reimport a fresh copy into a DataFrame\n","\n","# Next, remove all columns that are not numeric. Once quick way to do that is using the np.number method of the numpy package: df.select_dtypes(np.number)\n","\n","# Also, remove loan_status_numeric from the DataFrame since that is typically considered a label and we are going to generate our own cluster/label.\n","\n","# After completing the prior step, remove all rows that contain any null values (see the example code given to you above).\n","\n","# Finally, scale the remaining DataFrame using a MinMaxScalar().\n","\n","# Print the first 5 records. What is the loan amount of the second row after scaling (Index 1)?\n","\n"]},{"cell_type":"code","execution_count":100,"metadata":{"id":"dI765B7XCw94"},"outputs":[],"source":["# Question 27: Next, let's perform a Silhouette analysis to determine the optimal number of clusters. Calculate a silhouette score for KMeans models with n number of clusters = 2 though 20. Plot the results. What is the optimal number of clusters?\n"]},{"cell_type":"code","execution_count":101,"metadata":{"id":"wiVP7-_WQeBQ"},"outputs":[],"source":["# Question 28: Generate a KMeans model using two clusters and a random seed of 12345. Add the assigned clusters as a new column in DataFrame.\n","\n","# Which cluster has the most assigned cases? \n"]},{"cell_type":"code","execution_count":102,"metadata":{"id":"wHTumjN8XMzA"},"outputs":[],"source":["# Question 29: Create a new DataFrame that displays the means of each feature seperately for the cases assigned both clusters (just like the example in the book). \n","\n","# Which features played the largest role in determining clusters? Copy and paste the full name below exactly as it appears with no leading or trailing spaces.\n","\n"]},{"cell_type":"code","execution_count":103,"metadata":{"id":"gWyhUQ7BYTAJ"},"outputs":[],"source":["# Question 30: What is the predicted/assigned cluster for a new loan with the following values:? [0.9, 0.33, 0.34, 0.30, 0.25, 0.17, 1.0, 0.18, 0.0, 0.0, 0.0, 0.37, 0.54, 0.17, 0.04, 0.08, 0.70, 1.0, 0.02, 0.23, 0.12, 0.05]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ly-I5as60RLh"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Modeling_Midterm.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":0}
